{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52551d1d-9446-4db5-8b82-a125baea80d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from dataset import Thyroid_Dataset\n",
    "from model import Eff_Unet\n",
    "from HarDMSEG import HarDMSEG\n",
    "from loss_metric import DiceLoss, IOU_score, StructureLoss\n",
    "from LightMed.model.LightMed import LightMed\n",
    "from PMFSNet.lib.models.PMFSNet import PMFSNet\n",
    "from PMFSNet.lib.models.PMFSNet_FFT import PMFSNet_FFT\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as tx\n",
    "from hybrid_model_v3 import HybridSegModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3ae27d1-8a24-4ce1-a6ef-b9c4a7abc5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as tx\n",
    "import random\n",
    "import cv2\n",
    "from PIL import ImageEnhance\n",
    "from skimage.exposure import match_histograms\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "class Gland_Dataset(Dataset):\n",
    "    def __init__(self, csv_file, transform, image_size):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.image_size = image_size\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.df[\"image_name\"][idx]\n",
    "        mask_name = self.df[\"mask_name\"][idx]\n",
    "\n",
    "        from_folder = \"../gland_data\"\n",
    "        \n",
    "        image_path = f\"{from_folder}/images/{image_name}\"\n",
    "        mask_path = f\"{from_folder}/masks/{mask_name}\"\n",
    "\n",
    "        image = Image.open(image_path).convert(\"L\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        \n",
    "        image_tensor, mask_tensor = self.transform(image, mask, self.image_size)\n",
    "        mask_tensor = (mask_tensor > 0.5).float()\n",
    "        if torch.sum(mask_tensor) == 0:\n",
    "            # print(\"nothing\")\n",
    "            return [None]\n",
    "        return image_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "248dde1d-68d5-4fa1-96f0-94c0408334e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a327316f-dc4a-4787-93c2-94866cec88ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "batch_size = 1 # if not one, be careful about the zero mask batch\n",
    "def test_augmentation(image, mask, image_size):\n",
    "    resize = T.Resize((image_size, image_size))\n",
    "    image = resize(image)\n",
    "    mask = resize(mask)\n",
    "\n",
    "    image_tensor = tx.to_tensor(image)\n",
    "    mask_tensor = tx.to_tensor(mask)\n",
    "\n",
    "    # If standardization\n",
    "    mean = image_tensor.mean()\n",
    "    std = image_tensor.std()\n",
    "    std = std if std > 0 else 1.0  # avoid division by zero\n",
    "    image_tensor = (image_tensor - mean) / std\n",
    "    return image_tensor, mask_tensor\n",
    "def custom_collate_fn(batch):\n",
    "    # print(batch)\n",
    "    filtered_batch = [item for item in batch if item[0] is not None]\n",
    "    if len(filtered_batch) == 0:\n",
    "        return [None, None]\n",
    "    return torch.utils.data.dataloader.default_collate(filtered_batch)\n",
    "tg3k_test_dataset = Gland_Dataset(\"../gland_data/tg3k_all.csv\", transform = test_augmentation, image_size = image_size)\n",
    "tg3k_test_dataloader = DataLoader(tg3k_test_dataset, batch_size = batch_size, shuffle = False, collate_fn=custom_collate_fn)\n",
    "\n",
    "benq_test_dataset = Gland_Dataset(\"../gland_data/benq_all.csv\", transform = test_augmentation, image_size = image_size)\n",
    "benq_test_dataloader = DataLoader(benq_test_dataset, batch_size = batch_size, shuffle = False, collate_fn=custom_collate_fn)\n",
    "\n",
    "image, mask = next(iter(tg3k_test_dataloader))\n",
    "image, mask = next(iter(benq_test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47edc937-3f17-4110-b4aa-c27f96849fba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std :  tensor(1.)\n",
      "unique :  tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(\"std : \", torch.std(image))\n",
    "print(\"unique : \", torch.unique(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "866b13ef-a7b4-44f2-856a-8d22eeea2006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(20):\n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.imshow(image[i][0])\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.imshow(mask[i][0])\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d1d16cd-aa05-4c5e-9736-0cdbb02529a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only calculate nodule loss, IOU, DICE, because there is no gland data in the testing set\n",
    "def val(dataloader, model, loss_fn, device):\n",
    "    total_loss = 0\n",
    "    \n",
    "    total_IOU = 0\n",
    "    \n",
    "    total_DICE = 0\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    dice_arr = []\n",
    "    count = 0\n",
    "    for image, mask in tqdm(dataloader):\n",
    "        if image == None:\n",
    "            continue\n",
    "        image, mask = image.to(device), mask.to(device)\n",
    "        outputs = model(image)\n",
    "        \n",
    "        output = outputs[:, 1:2, :, :]\n",
    "        \n",
    "        \n",
    "        loss = loss_fn(output, mask)\n",
    "\n",
    "        \n",
    "        IOU = IOU_score(output, mask)\n",
    "\n",
    "\n",
    "        dice_loss = DiceLoss()\n",
    "        DICE = 1 - dice_loss(output, mask)\n",
    "        \n",
    "        dice_arr.append(DICE.item())\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        total_IOU += IOU.item()\n",
    "        \n",
    "        total_DICE += DICE.item()\n",
    "        count += 1\n",
    "    return total_loss/count, total_IOU/count, total_DICE/count\n",
    "    # return total_loss/len(dataloader), total_IOU/len(dataloader), total_DICE/len(dataloader), dice_arr\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee92f3-d247-4b75-a51e-eabf5c68f7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c58a8697-c3e8-414c-9ed8-722bc4edf44d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_name = \"models/Phase 1/Hybrid_crop_DDTI_standardization_aug_affine(0.5)_for_gland\"\n",
    "model = HybridSegModel(in_channels = 1, out_channels = 2, output_size = image_size, layers_num = 3)\n",
    "checkpoint = torch.load(f\"{inference_name}/best_checkpoint.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e84c5aa-badd-4626-93f8-b4d23ee5afcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twszbak764/miniconda3/envs/thyroid/lib/python3.12/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "100%|██████████| 3500/3500 [01:33<00:00, 37.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss : 0.14675314565002917, val IOU : 0.8845921107856047, val DICE : 0.9273581279686519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = StructureLoss()\n",
    "total_loss_val, total_IOU_val, total_DICE_val = val(tg3k_test_dataloader, model, loss_fn, \"cuda\")\n",
    "print(f\"val loss : {total_loss_val}, val IOU : {total_IOU_val}, val DICE : {total_DICE_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310fc306-3e47-4e0e-8fec-a5f6b6e06488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f158900f-e057-488b-a8a1-2253bd59ae8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a4ad76d-1137-4a70-ae2e-4e606f192ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 466/466 [00:17<00:00, 27.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss : 1.0401062751883892, val IOU : 0.41252591694650476, val DICE : 0.5369991314648396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = StructureLoss()\n",
    "total_loss_val, total_IOU_val, total_DICE_val = val(benq_test_dataloader, model, loss_fn, \"cuda\")\n",
    "print(f\"val loss : {total_loss_val}, val IOU : {total_IOU_val}, val DICE : {total_DICE_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91c54c-cbed-4f81-9f41-5e9d83c4fec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thyroid",
   "language": "python",
   "name": "thyroid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
