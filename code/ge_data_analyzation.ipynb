{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbada50d-1e33-4c43-898d-674a7a1cbd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thyroid/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/anaconda3/envs/thyroid/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/opt/anaconda3/envs/thyroid/lib/python3.12/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from dataset import Thyroid_Dataset\n",
    "from model import Eff_Unet\n",
    "from HarDMSEG import HarDMSEG\n",
    "from loss_metric import DiceLoss, IOU_score, StructureLoss\n",
    "from LightMed.model.LightMed import LightMed\n",
    "from PMFSNet.lib.models.PMFSNet import PMFSNet\n",
    "from PMFSNet.lib.models.PMFSNet_FFT import PMFSNet_FFT\n",
    "from hybrid_model_v3 import HybridSegModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "552e0837-3243-45a8-af13-0dd8363d8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7db1b35-7517-4305-8612-c910a0093bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as tx\n",
    "import random\n",
    "import cv2\n",
    "from PIL import ImageEnhance\n",
    "from skimage.exposure import match_histograms\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "class GE_Thyroid_Dataset(Dataset):\n",
    "    def __init__(self, csv_file, transform, image_size):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.image_size = image_size\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.df[\"image_name\"][idx]\n",
    "        mask_name = self.df[\"mask_name\"][idx]\n",
    "        image_type = self.df[\"image_type\"][idx]\n",
    "\n",
    "        if image_type == \"train\":\n",
    "            from_folder = \"../ge_data/train\"\n",
    "        else:\n",
    "            from_folder = \"../ge_data/test\"\n",
    "        \n",
    "        image_path = f\"{from_folder}/images/{image_name}\"\n",
    "        mask_path = f\"{from_folder}/masks/{mask_name}\"\n",
    "\n",
    "        image = Image.open(image_path).convert(\"L\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        \n",
    "        image_tensor, mask_tensor = self.transform(image, mask, self.image_size)\n",
    "        mask_tensor = (mask_tensor > 0.5).float()\n",
    "        if torch.sum(mask_tensor) == 0:\n",
    "            # print(\"nothing\")\n",
    "            return [None]\n",
    "        return image_tensor, mask_tensor, mask_name, image_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73eef130-f914-4c3f-8670-99dff492b23e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "batch_size = 1\n",
    "def train_augmentation(image, mask, image_size):\n",
    "    resize = T.Resize((image_size, image_size))\n",
    "    image = resize(image)\n",
    "    mask = resize(mask)\n",
    "\n",
    "    p = 0.2\n",
    "    \n",
    "    # if(random.random() < p):\n",
    "    #     jitter = T.ColorJitter(brightness = 0.5, contrast = 0.25)\n",
    "    #     image = jitter(image)\n",
    "    # if(random.random() < p):\n",
    "    #     transform = T.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
    "    #     image = transform(image)  # image must be a PIL image\n",
    "    # if(random.random() < p):\n",
    "    #     angle = random.uniform(-10, 10)  # 旋轉角度從 ±10 度\n",
    "    #     translate = (random.uniform(-0.05, 0.05) * image.size[0],\n",
    "    #                  random.uniform(-0.05, 0.05) * image.size[1])  # 最多平移 ±5%\n",
    "    #     scale = random.uniform(0.95, 1.05)  # 尺度縮放 ±5%\n",
    "    #     shear = [random.uniform(-5, 5), random.uniform(-5, 5)]  # 小幅剪切\n",
    "    \n",
    "    #     image = F.affine(image, angle=angle, translate=translate, scale=scale, shear=shear)\n",
    "    #     mask = F.affine(mask, angle=angle, translate=translate, scale=scale, shear=shear)\n",
    "\n",
    "        \n",
    "    image_tensor = tx.to_tensor(image)\n",
    "    mask_tensor = tx.to_tensor(mask)\n",
    "\n",
    "    # If standardization\n",
    "    # mean = image_tensor.mean()\n",
    "    # std = image_tensor.std()\n",
    "    # std = std if std > 0 else 1.0  # avoid division by zero\n",
    "    # image_tensor = (image_tensor - mean) / std\n",
    "    return image_tensor, mask_tensor\n",
    "def test_augmentation(image, mask, image_size):\n",
    "    resize = T.Resize((image_size, image_size))\n",
    "    image = resize(image)\n",
    "    mask = resize(mask)\n",
    "\n",
    "    image_tensor = tx.to_tensor(image)\n",
    "    mask_tensor = tx.to_tensor(mask)\n",
    "\n",
    "    # If standardization\n",
    "    # mean = image_tensor.mean()\n",
    "    # std = image_tensor.std()\n",
    "    # std = std if std > 0 else 1.0  # avoid division by zero\n",
    "    # image_tensor = (image_tensor - mean) / std\n",
    "    return image_tensor, mask_tensor\n",
    "def custom_collate_fn(batch):\n",
    "    # print(batch)\n",
    "    filtered_batch = [item for item in batch if item[0] is not None]\n",
    "    if len(filtered_batch) == 0:\n",
    "        return [None, None, None, None]\n",
    "    return torch.utils.data.dataloader.default_collate(filtered_batch)\n",
    "train_dataset = GE_Thyroid_Dataset(\"../ge_data/train_csv_for_finetune(1).csv\", transform = train_augmentation, image_size = image_size)\n",
    "# train_dataset = GE_Thyroid_Dataset(\"../ge_data/test_csv_for_finetune_all.csv\", transform = train_augmentation, image_size = image_size)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, collate_fn=custom_collate_fn)\n",
    "\n",
    "test_dataset = GE_Thyroid_Dataset(\"../ge_data/test_csv_for_finetune_all.csv\", transform = test_augmentation, image_size = image_size)\n",
    "# test_dataset = GE_Thyroid_Dataset(\"../ge_data/train_csv_for_finetune(0.3).csv\", transform = test_augmentation, image_size = image_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, collate_fn=custom_collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da0e1427-6dc3-41fc-a80d-bc9bea2dc4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cee5b6f8-749e-4964-862a-255a44883a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565 112\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03559269-62df-4462-87f3-7fbaa577297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(mask):\n",
    "    row = []\n",
    "    col = []\n",
    "    for i in range(mask.shape[0]):\n",
    "        for j in range(mask.shape[1]):\n",
    "            if mask[i][j]:\n",
    "                row.append(i)\n",
    "                col.append(j)\n",
    "    return np.mean(row), np.mean(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85b58550-f8c4-49cc-bf06-9f1fad998b2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 565/565 [00:11<00:00, 49.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean :  0.17272177\n",
      "train std :  0.19266826\n",
      "train size ratio :  0.05343415\n",
      "train row :  35.85483061201079\n",
      "train col :  62.27568023225343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_mean = []\n",
    "train_std = []\n",
    "train_size_ratio = []\n",
    "train_row = []\n",
    "train_col = []\n",
    "for image_tensor, mask_tensor, mask_name, image_type in tqdm(train_dataloader):\n",
    "    # print(image_tensor)\n",
    "    if image_tensor == None:\n",
    "        continue\n",
    "    mean = torch.mean(image_tensor[0][0])\n",
    "    std = torch.std(image_tensor[0][0])\n",
    "    size_ratio = torch.sum(mask_tensor[0][0]) / (mask_tensor[0][0].shape[0] * mask_tensor[0][0].shape[1])\n",
    "    row, col = get_pos(mask_tensor[0][0])\n",
    "    train_row.append(row)\n",
    "    train_col.append(col)\n",
    "    train_mean.append(mean)\n",
    "    train_std.append(std)\n",
    "    train_size_ratio.append(size_ratio)\n",
    "print(\"train mean : \", np.mean(train_mean))\n",
    "print(\"train std : \", np.mean(train_std))\n",
    "print(\"train size ratio : \", np.mean(train_size_ratio))\n",
    "print(\"train row : \", np.mean(train_row))\n",
    "print(\"train col : \", np.mean(train_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f72dc91c-c1fb-4a55-938d-59b71487319b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 112/112 [00:02<00:00, 48.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean :  0.1537063\n",
      "test std :  0.15427291\n",
      "test size ratio :  0.0825576\n",
      "test row :  46.099830831116854\n",
      "test col :  64.7797866359704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_mean = []\n",
    "test_std = []\n",
    "test_size_ratio = []\n",
    "test_row = []\n",
    "test_col = []\n",
    "for image_tensor, mask_tensor, mask_name, image_type in tqdm(test_dataloader):\n",
    "    # print(image_tensor)\n",
    "    if image_tensor == None:\n",
    "        continue\n",
    "    mean = torch.mean(image_tensor[0][0])\n",
    "    std = torch.std(image_tensor[0][0])\n",
    "    size_ratio = torch.sum(mask_tensor[0][0]) / (mask_tensor[0][0].shape[0] * mask_tensor[0][0].shape[1])\n",
    "    row, col = get_pos(mask_tensor[0][0])\n",
    "    test_row.append(row)\n",
    "    test_col.append(col)\n",
    "    test_mean.append(mean)\n",
    "    test_std.append(std)\n",
    "    test_size_ratio.append(size_ratio)\n",
    "print(\"test mean : \", np.mean(test_mean))\n",
    "print(\"test std : \", np.mean(test_std))\n",
    "print(\"test size ratio : \", np.mean(test_size_ratio))\n",
    "print(\"test row : \", np.mean(test_row))\n",
    "print(\"test col : \", np.mean(test_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04303d71-6949-4511-9cec-d07bb32545a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thyroid",
   "language": "python",
   "name": "thyroid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
