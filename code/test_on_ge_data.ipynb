{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52551d1d-9446-4db5-8b82-a125baea80d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twszbak764/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/twszbak764/.local/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/home/twszbak764/.local/lib/python3.12/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from dataset import Thyroid_Dataset\n",
    "from model import Eff_Unet\n",
    "from HarDMSEG import HarDMSEG\n",
    "from loss_metric import DiceLoss, IOU_score, StructureLoss\n",
    "from LightMed.model.LightMed import LightMed\n",
    "from PMFSNet.lib.models.PMFSNet import PMFSNet\n",
    "from PMFSNet.lib.models.PMFSNet_FFT import PMFSNet_FFT\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as tx\n",
    "from hybrid_model_v3_upsample import HybridSegModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ae27d1-8a24-4ce1-a6ef-b9c4a7abc5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as tx\n",
    "import random\n",
    "import cv2\n",
    "from PIL import ImageEnhance\n",
    "from skimage.exposure import match_histograms\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "class GE_Thyroid_Dataset(Dataset):\n",
    "    def __init__(self, csv_file, transform, image_size):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.image_size = image_size\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.df[\"image_name\"][idx]\n",
    "        mask_name = self.df[\"mask_name\"][idx]\n",
    "        image_type = self.df[\"image_type\"][idx]\n",
    "\n",
    "        if image_type == \"train\":\n",
    "            from_folder = \"../ge_data/train\"\n",
    "        else:\n",
    "            from_folder = \"../ge_data/test\"\n",
    "\n",
    "        image_path = f\"{from_folder}/images/{image_name}\"\n",
    "        mask_path = f\"{from_folder}/masks/{mask_name}\"\n",
    "\n",
    "        image = Image.open(image_path).convert(\"L\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        \n",
    "        image_tensor, mask_tensor = self.transform(image, mask, self.image_size)\n",
    "        mask_tensor = (mask_tensor > 0.5).float()\n",
    "\n",
    "        return image_tensor, mask_tensor, mask_name, image_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248dde1d-68d5-4fa1-96f0-94c0408334e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a327316f-dc4a-4787-93c2-94866cec88ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "batch_size = 1 # if not one, be careful about the zero mask batch\n",
    "def test_augmentation(image, mask, image_size):\n",
    "    resize = T.Resize((image_size, image_size))\n",
    "    image = resize(image)\n",
    "    mask = resize(mask)\n",
    "\n",
    "    image_tensor = tx.to_tensor(image)\n",
    "    mask_tensor = tx.to_tensor(mask)\n",
    "\n",
    "    # If standardization\n",
    "    mean = image_tensor.mean()\n",
    "    std = image_tensor.std()\n",
    "    std = std if std > 0 else 1.0  # avoid division by zero\n",
    "    image_tensor = (image_tensor - mean) / std\n",
    "    return image_tensor, mask_tensor\n",
    "\n",
    "test_dataset = GE_Thyroid_Dataset(\"../ge_data/all_data.csv\", transform = test_augmentation, image_size = image_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "image, mask, mask_name, image_type = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47edc937-3f17-4110-b4aa-c27f96849fba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std :  tensor(1.)\n",
      "unique :  tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "print(\"std : \", torch.std(image))\n",
    "print(\"unique : \", torch.unique(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866b13ef-a7b4-44f2-856a-8d22eeea2006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(20):\n",
    "#     print(mask_name[i])\n",
    "#     print(image_type[i])\n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.imshow(image[i][0])\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.imshow(mask[i][0])\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d1d16cd-aa05-4c5e-9736-0cdbb02529a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only calculate nodule loss, IOU, DICE, because there is no gland data in the testing set\n",
    "def val(dataloader, model, loss_fn, device):\n",
    "    total_loss = 0\n",
    "    \n",
    "    total_IOU = 0\n",
    "    \n",
    "    total_DICE = 0\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    dice_arr = []\n",
    "    count = 0\n",
    "    for image, mask, mask_name, image_type in tqdm(dataloader):\n",
    "        image, mask = image.to(device), mask.to(device)\n",
    "        if torch.sum(mask) == 0:\n",
    "            continue\n",
    "        outputs = model(image)\n",
    "        \n",
    "        output = outputs[:, 0:1, :, :]\n",
    "        \n",
    "        \n",
    "        loss = loss_fn(output, mask)\n",
    "\n",
    "        \n",
    "        IOU = IOU_score(output, mask)\n",
    "\n",
    "\n",
    "        dice_loss = DiceLoss()\n",
    "        DICE = 1 - dice_loss(output, mask)\n",
    "        \n",
    "        dice_arr.append(DICE.item())\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        total_IOU += IOU.item()\n",
    "        \n",
    "        total_DICE += DICE.item()\n",
    "        count += 1\n",
    "    # return total_loss/count, total_IOU/count, total_DICE/count, dice_arr\n",
    "    return total_loss/len(dataloader), total_IOU/len(dataloader), total_DICE/len(dataloader), dice_arr\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee92f3-d247-4b75-a51e-eabf5c68f7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c58a8697-c3e8-414c-9ed8-722bc4edf44d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference_name = \"PMFSNet_crop_DDTI_standardization_aug_affine(0.5)_for_gland\"\n",
    "inference_name = \"hybrid_v3_upsample_baseline\"\n",
    "# inference_name = \"HarDnetMSEG_baseline\"\n",
    "model = HybridSegModel(in_channels = 1, out_channels = 2, output_size = image_size, layers_num = 3)\n",
    "# model = HarDMSEG(in_channels = 1, out_channels = 2)\n",
    "# model = PMFSNet(in_channels = 1, out_channels = 2, dim = \"2d\")\n",
    "# model = PMFSNet_FFT(in_channels = 1, out_channels = 2, dim = \"2d\")\n",
    "# model = LightMed(in_channels = 1, out_channels = 1, image_size = image_size)\n",
    "checkpoint = torch.load(f\"models/{inference_name}/best_checkpoint.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# scheduler.load_state_dict(checkpoint['scheduler_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e84c5aa-badd-4626-93f8-b4d23ee5afcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twszbak764/miniconda3/envs/thyroid/lib/python3.12/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "100%|██████████| 677/677 [00:28<00:00, 23.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss : 0.8529006734468384, val IOU : 0.5138420756662573, val DICE : 0.622985286145654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = StructureLoss()\n",
    "total_loss_val, total_IOU_val, total_DICE_val, dice_arr = val(test_dataloader, model, loss_fn, \"cpu\")\n",
    "print(f\"val loss : {total_loss_val}, val IOU : {total_IOU_val}, val DICE : {total_DICE_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a4ad76d-1137-4a70-ae2e-4e606f192ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dice_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d88465a7-8762-4c3e-a5db-445b0ed5bae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421.76103872060776"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(dice_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47814c-e2dc-41d4-93e5-610547438dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3782be09-4caa-4037-9a05-d3521c649aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421.76103872060776"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_DICE_val * len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b47c87-46a5-4424-9bc0-219c5082b3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99199fca-b62b-4fe0-8a1e-e01ca4d0c0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34b40112-8729-4a96-a2d9-de17929d26a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6ff23ba-7c6c-41aa-a9ca-a1b04e24864c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# image, mask, seg_type, from_dataset = next(iter(test_dataloader))\n",
    "model.to(\"cpu\")\n",
    "outputs = model(image)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cba01cb-4a60-46d2-9b70-25e2459925be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'from_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m from_dataset\n",
      "\u001b[31mNameError\u001b[39m: name 'from_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d595d244-7f5e-48e4-8e43-911b055e2408",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs = [9, 15, 2, 8]\n",
    "for index in indexs:\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image[index][0])\n",
    "    plt.imshow(mask[index][0], alpha = 0.5)\n",
    "    plt.title(\"label\")\n",
    "    \n",
    "    outputs = outputs>0.5\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(image[index][0])\n",
    "    plt.imshow(outputs[index][0].detach().cpu().numpy(), alpha = 0.5)\n",
    "    plt.title(\"prediction\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e719a12-bce2-469f-bc18-8432def10e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ead520-cb62-4cd8-b5b4-11444f162d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c202797-d20e-4e96-b301-7ad867afa83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDTI_area_ratio = []\n",
    "TN3K_area_ratio = []\n",
    "DDTI_image_mean = []\n",
    "TN3K_image_mean = []\n",
    "for image, mask, seg_type, from_dataset in tqdm(test_dataloader):\n",
    "    for i in range(image.shape[0]):\n",
    "        if from_dataset[i]==1:\n",
    "            # plt.imshow(image[i][0])\n",
    "            # plt.show()\n",
    "            DDTI_area_ratio.append(torch.sum(mask[i][0])/(mask.shape[2]*mask.shape[3]))\n",
    "            DDTI_image_mean.append(torch.mean(image[i][0]))\n",
    "        elif from_dataset[i]==3:\n",
    "            TN3K_area_ratio.append(torch.sum(mask[i][0])/(mask.shape[2]*mask.shape[3]))\n",
    "            TN3K_image_mean.append(torch.mean(image[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca34329c-6048-4693-973f-3eb07aa41edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDTI_area_ratio = []\n",
    "TN3K_area_ratio = []\n",
    "DDTI_image_mean = []\n",
    "TN3K_image_mean = []\n",
    "DDTI_image_std = []\n",
    "TN3K_image_std = []\n",
    "for image, mask, seg_type, from_dataset in tqdm(test_dataloader):\n",
    "    for i in range(image.shape[0]):\n",
    "        if from_dataset[i]==1:\n",
    "            # plt.imshow(image[i][0])\n",
    "            # plt.show()\n",
    "            DDTI_area_ratio.append(torch.sum(mask[i][0])/(mask.shape[2]*mask.shape[3]))\n",
    "            DDTI_image_mean.append(torch.mean(image[i][0]))\n",
    "            DDTI_image_std.append(torch.std(image[i][0]))\n",
    "        elif from_dataset[i]==3:\n",
    "            TN3K_area_ratio.append(torch.sum(mask[i][0])/(mask.shape[2]*mask.shape[3]))\n",
    "            TN3K_image_mean.append(torch.mean(image[i][0]))\n",
    "            TN3K_image_std.append(torch.std(image[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52601c8-a0a9-4df1-9ea4-48362bfb3439",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(DDTI_image_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de43e08-6916-4da7-8569-56bb51c2527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(TN3K_image_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8783af1-0b65-4927-85fa-3e0230f5fed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDTI_image_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ebad1-c0f2-4727-bb84-ff480d39bc04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(DDTI_area_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d975cb0-3bd6-42d6-9191-146bd746e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(TN3K_area_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f180063-0157-4161-918b-a31df00d4942",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(DDTI_image_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f2fd9-cf0d-458f-b0cf-eaa6118dcd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(TN3K_image_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c74bc9c-e813-4e51-8b40-d56af5a0bae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thyroid",
   "language": "python",
   "name": "thyroid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
